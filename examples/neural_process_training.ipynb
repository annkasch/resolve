{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from resolve.utilities import utilities as utils\n",
    "from resolve.helpers import DataLoaderManager\n",
    "from resolve.helpers import Trainer, ModelsManager\n",
    "from resolve.helpers import AsymmetricFocalWithFPPenalty, log_prob, recon_loss_mse, skip_loss, bce_with_logits, brier\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import yaml\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the yaml settings file here\n",
    "path_to_settings = \"./binary-black-hole/\"\n",
    "with open(f\"{path_to_settings}/settings.yaml\", \"r\") as f:\n",
    "    config_file = yaml.safe_load(f)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "version = config_file[\"path_settings\"][\"version\"]\n",
    "path_out = f'{config_file[\"path_settings\"][\"path_out_model\"]}/model-{version}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config_file[\"model_settings\"][\"network\"][\"model_used\"]\n",
    "network_config = config_file[\"model_settings\"][\"network\"][\"models\"][model_name]\n",
    "network_config[\"d_y\"] = utils.get_feature_and_label_size(config_file)[1]\n",
    "network_config[\"d_theta\"]  = len(config_file[\"simulation_settings\"][\"theta_labels\"])\n",
    "network_config[\"d_phi\"] = len(config_file[\"simulation_settings\"][\"phi_labels\"])\n",
    "\n",
    "manager = ModelsManager(network_config)\n",
    "model = manager.get_network(config_file[\"model_settings\"][\"network\"][\"model_used\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HCTargetAttnNP(\n",
       "  (ctx_enc): ContextConditionalEncoder(\n",
       "    (theta_enc): ThetaEncoder(\n",
       "      (mlp): MLP(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_layers): ModuleList(\n",
       "      (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (film_layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=64, out_features=256, bias=True)\n",
       "    )\n",
       "    (final): Identity()\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (theta_enc_t): ThetaEncoder(\n",
       "    (mlp): MLP(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tquery): TargetQueryEncoder(\n",
       "    (theta_enc): ThetaEncoder(\n",
       "      (mlp): MLP(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): ReLU()\n",
       "          (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mlp): MLP(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=138, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attn): GlobalContextAttentionDual(\n",
       "    (Wq): Linear(in_features=128, out_features=128, bias=False)\n",
       "    (Wk): Linear(in_features=128, out_features=128, bias=False)\n",
       "    (Wv): Linear(in_features=128, out_features=128, bias=False)\n",
       "    (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (tgt_enc): TargetEncoder(\n",
       "    (theta_enc): ThetaEncoder(\n",
       "      (mlp): MLP(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): ReLU()\n",
       "          (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mlp): MLP(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=394, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): BernoulliHead(\n",
       "    (net): MLP(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta mean:  [1.50423200e-02 4.99557795e+00 5.00162000e+02 4.98470000e+02]\n",
      "phi mean:  [3.09912000e-02 1.38451402e+01 7.49881529e+01 3.83905393e+01\n",
      " 1.93798800e-01 5.03367206e-01 1.08481965e+02 1.17347808e+01\n",
      " 1.09972412e+01 9.90653600e-01]\n"
     ]
    }
   ],
   "source": [
    "# load data:\n",
    "dataset_train = DataLoaderManager(mode = \"train\", \n",
    "                                config_file=config_file\n",
    "                                )\n",
    "\n",
    "dataset_train.set_dataset(shuffle=config_file[\"model_settings\"][\"train\"][\"dataset\"][\"shuffle_dataset\"])\n",
    "\n",
    "if config_file[\"model_settings\"][\"train\"][\"dataset\"][\"use_feature_normalization\"] == \"zscore\":\n",
    "    print(\"theta mean: \", dataset_train.dataset._normalizer._get_scaler(\"theta\").mean_)\n",
    "    print(\"phi mean: \", dataset_train.dataset._normalizer._get_scaler(\"phi\").mean_)\n",
    "elif config_file[\"model_settings\"][\"train\"][\"dataset\"][\"use_feature_normalization\"] == \"minmax\":\n",
    "    print(\"theta mean: \", dataset_train.dataset._normalizer._get_scaler(\"theta\").data_range_)\n",
    "    print(\"phi mean: \", dataset_train.dataset._normalizer._get_scaler(\"phi\").data_range_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'mkdir -p {path_out}/model_{version}_tensorboard_logs')\n",
    "os.system(f'rm {path_out}/model_{version}_tensorboard_logs/events*')\n",
    "writer = SummaryWriter(log_dir=f'{path_out}/model_{version}_tensorboard_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 751 ms, sys: 402 ms, total: 1.15 s\n",
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = None if model.__class__.__name__ == \"IsolationForestWrapper\" else optim.Adam(model.parameters(), lr=config_file[\"model_settings\"][\"train\"][\"learning_rate\"])\n",
    "\n",
    "# Instantiate the training wrapper for the first phase\n",
    "trainer = Trainer(model, dataset_train)\n",
    "\n",
    "trainer.epochs = config_file[\"model_settings\"][\"train\"][\"training_epochs\"]\n",
    "\n",
    "if isinstance(utils.get_nested(config_file, [\"model_settings\",\"train\",\"dataset\",\"positive_ratio_train\"], False), list):\n",
    "        trainer.criterion = AsymmetricFocalWithFPPenalty(\n",
    "                        alpha_pos=1.,\n",
    "                        alpha_neg=1.,\n",
    "                        gamma_pos=0.,\n",
    "                        gamma_neg=0.,\n",
    "                        lambda_fp=0.,\n",
    "                        tau_fp=0.5,\n",
    "                        lambda_tp= 5.,\n",
    "                        tau_tp=0.5,\n",
    "                        reduction=utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"reduction\"], \"mean\"),\n",
    "                        base_loss_fn=globals()[utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"base_loss_fn\"], \"bce_with_logits\")],\n",
    "                )\n",
    "\n",
    "        if utils.get_nested(config_file, [\"model_settings\",\"train\",\"dataset\",\"skip_warmup\"], False) == True:\n",
    "                print(\"loading warm up\")\n",
    "                model.load_state_dict(torch.load(f'{path_out}/model_{version}_warmup_model.pth'))\n",
    "        else:\n",
    "                # Train the model\n",
    "                summary_train = trainer.warm_up(target_pos_frac = utils.get_nested(config_file, [\"model_settings\",\"train\",\"dataset\",\"positive_ratio_train\"], None),\n",
    "                        optimizer= optimizer,\n",
    "                        writer=writer,\n",
    "                        monitor = \"pr_auc\",\n",
    "                        mode = \"max\",\n",
    "                        save_best = True,\n",
    "                        patience = 20,\n",
    "                        num_data_pass_per_phase = utils.get_nested(config_file, [\"model_settings\",\"train\",\"dataset\",\"num_data_pass_per_phase\"], 1.)\n",
    "                )\n",
    "\n",
    "                torch.save(model.state_dict(), f'{path_out}/model_{version}_warmup_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 1/1: 100%|██████████| 3000/3000 [00:58<00:00, 50.93it/s, loss=0.0008]\n",
      "validate 1: 100%|██████████| 1000/1000 [00:12<00:00, 78.78it/s, loss=0.0004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.6 s, sys: 10.9 s, total: 1min 6s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.criterion = AsymmetricFocalWithFPPenalty(\n",
    "                alpha_pos=utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"alpha_pos\"], 1.),\n",
    "                alpha_neg=utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"alpha_neg\"], 1.),\n",
    "                gamma_pos=utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"gamma_pos\"], 0.),\n",
    "                gamma_neg=utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"gamma_neg\"], 0.),\n",
    "                lambda_fp=utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"lambda_fp\"],0.),\n",
    "                tau_fp=utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"tau_fp\"],0.5),\n",
    "                lambda_tp=utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"lambda_tp\"],0.),\n",
    "                tau_tp=utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"tau_tp\"],0.5),\n",
    "                reduction=utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"reduction\"], \"mean\"),\n",
    "                base_loss_fn=globals()[utils.get_nested(config_file, [\"model_settings\",\"train\",\"loss\",\"base_loss_fn\"], \"bce_with_logits\")],\n",
    "            )\n",
    "\n",
    "# Train the model\n",
    "summary_train = trainer.fit(optimizer=optimizer, patience = config_file[\"model_settings\"][\"train\"][\"patience\"], writer=writer, ckpt_dir=f\"{path_out}/checkpoints\", ckpt_name=f\"model_{version}_best.pt\",\n",
    "        monitor=\"pr_auc\", mode=\"max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.1474059969934624,\n",
       " 'monitor': 'pr_auc',\n",
       " 'mode': 'max',\n",
       " 'epochs_ran': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 0: 100%|██████████| 1000/1000 [00:12<00:00, 78.67it/s, loss=0.0004]\n"
     ]
    }
   ],
   "source": [
    "_ = trainer.evaluate(writer=writer, dataset_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.992684,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'f1': 0.0,\n",
       " 'roc_auc': 0.9583133457519003,\n",
       " 'roc_curve': [array([0.00000000e+00, 0.00000000e+00, 1.00736992e-06, ...,\n",
       "         9.99887175e-01, 9.99889189e-01, 1.00000000e+00]),\n",
       "  array([0.00000000e+00, 1.36686714e-04, 1.36686714e-04, ...,\n",
       "         1.00000000e+00, 1.00000000e+00, 1.00000000e+00])],\n",
       " 'pr_auc': 0.14638637376226382,\n",
       " 'precision_recall_curve': [array([0.007316  , 0.00731601, 0.00731601, ..., 0.5       , 1.        ,\n",
       "         1.        ]),\n",
       "  array([1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "         1.36686714e-04, 1.36686714e-04, 0.00000000e+00]),\n",
       "  0.007316],\n",
       " 'loss': 0.0003755245533052314}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.metrics[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 1: 100%|██████████| 1000/1000 [00:13<00:00, 74.12it/s, loss=0.0004]\n"
     ]
    }
   ],
   "source": [
    "normalizer_train = dataset_train.dataset._normalizer\n",
    "\n",
    "# load data:\n",
    "dataset_test = DataLoaderManager(mode = \"test\", \n",
    "                                config_file=config_file\n",
    "                                )\n",
    "dataset_test.set_dataset(normalizer=normalizer_train, shuffle=config_file[\"model_settings\"][\"train\"][\"dataset\"][\"shuffle_dataset\"])\n",
    "\n",
    "tester = Trainer(model, dataset_test, epochs=1)\n",
    "tester._report = 1\n",
    "tester.criterion = trainer.criterion\n",
    "\n",
    "# Train the model\n",
    "summary_test = tester.evaluate(dataset_name=\"test\", epoch=1, monitor=\"pr_auc\",writer=writer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.metrics['test_2'] = tester.metrics.pop('test')\n",
    "trainer.metrics |= tester.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.992304,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'f1': 0.0,\n",
       " 'roc_auc': 0.9592290550299638,\n",
       " 'roc_curve': [array([0.00000000e+00, 0.00000000e+00, 1.00775569e-06, ...,\n",
       "         9.99933488e-01, 9.99935504e-01, 1.00000000e+00]),\n",
       "  array([0.0000000e+00, 1.2993763e-04, 1.2993763e-04, ..., 1.0000000e+00,\n",
       "         1.0000000e+00, 1.0000000e+00])],\n",
       " 'pr_auc': 0.162258674858202,\n",
       " 'precision_recall_curve': [array([0.007696  , 0.00769601, 0.00769602, ..., 0.5       , 1.        ,\n",
       "         1.        ]),\n",
       "  array([1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ..., 1.2993763e-04,\n",
       "         1.2993763e-04, 0.0000000e+00]),\n",
       "  0.007696],\n",
       " 'loss': 0.00041274439470354187}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.metrics['test_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{path_out}/model_{version}_model.pth')\n",
    "with open(f'{path_out}/model_{version}_settings.yaml', \"w\") as f:\n",
    "    yaml.safe_dump(dataset_train.config_file, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_metrics = utils.make_json_safe(trainer.metrics)\n",
    "\n",
    "with open(f'{path_out}/model_{version}_train_metrics.json', \"w\") as f:\n",
    "    json.dump({model.__class__.__name__: safe_metrics}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.dataset.close()\n",
    "writer.close()\n",
    "utils.cleanup_workspace({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Start TensorBoard\n",
    "\n",
    "Run this in terminal:\n",
    "\n",
    "tensorboard --logdir=\\<path to tensor board log dir\\> --host=0.0.0.0 --port=7007\n",
    "\n",
    "Open:\n",
    "\n",
    "http://localhost:7007/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check effiency performance & memory use\n",
    "\n",
    "for memory:\n",
    "    \n",
    "    from memory_profiler import profile\n",
    "\n",
    "    @profile\n",
    "    def your_function():\n",
    "\n",
    "> python -m memory_profiler your_script.py  > mem_profile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> python -m cProfile -s tottime your_script.py\n",
    "> sudo py-spy top -- python your_script.py\n",
    " \n",
    "> sudo py-spy record -o loader.svg -- python your_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resolve-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
